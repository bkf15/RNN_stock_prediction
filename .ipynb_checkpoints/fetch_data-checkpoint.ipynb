{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-15 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from newsapi import NewsApiClient\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import pdb\n",
    "#define when data should be fetched from\n",
    "start = datetime(2020, 3, 15)#.strftime(\"%Y-%m-%d\")     #date to start getting stocks from\n",
    "end = datetime(2020, 4, 15)#.strftime(\"%Y-%m-%d\")       #date to stop\n",
    "print(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "#select companies to do testing on. trying to pick ones which may be relevant in the news\n",
    "\n",
    "#keywords[i]=term to search for when searching for news about companies[i]\n",
    "\n",
    "#list of companies and keywords. i looked at most active stocks on yahoo today\n",
    "ls = {\"AAL\" : [\"American Airlines\"],\n",
    "    \"GE\" : [\"General Electric\"],\n",
    "    \"DAL\" : [\"Delta Airlines\"],\n",
    "    \"BAC\" : [\"Bank of America\"],\n",
    "    \"AMD\" : [\"AMD\", \"Advanced micro devices\"],\n",
    "    \"F\" : [\"Ford\", \"Ford motor company\"],\n",
    "    \"CCL\" : [\"Carnival\", \"Carnival corporation\"],\n",
    "    \"UAL\" : [\"United airlines\"],\n",
    "    \"MRO\" : [\"Marathon oil\"],\n",
    "    \"MSFT\" : [\"Microsoft\"],\n",
    "    \"WFC\" : [\"Wells Fargo\"],\n",
    "    \"AAPL\" : [\"Apple\"],\n",
    "    \"BA\" : [\"Boeing\"],\n",
    "    \"JBLU\" : [\"JetBlue\"],\n",
    "    \"XOM\" : [\"Exxon Mobil\"],\n",
    "    \"T\" : [\"AT&T\"],\n",
    "    \"NOK\" : [\"Nokia\"],\n",
    "    \"JPM\" : [\"JP Morgan Chase\"],\n",
    "    \"RCL\" : [\"Royal Caribbean\"],\n",
    "    \"MGM\" : [\"MGM Resorts\"],\n",
    "    \"ZM\" : [\"Zoom Video Communications\", \"Zoom\"],\n",
    "    \"LUV\" : [\"Southwest Airlines\"],\n",
    "    \"BP\" : [\"BP\", \"British petroleum\"],\n",
    "    \"FB\" : [\"Facebook\", \"Instagram\"],\n",
    "    \"UBER\" : [\"Uber\"],\n",
    "    \"CZR\" : [\"Caesars Entertainment Corporation\t\", \"Caesars\"],\n",
    "    \"INTC\" : [\"Intel\"],\n",
    "    \"TEVA\" : [\"Teva\"],\n",
    "    \"ROKU\" : [\"Roku\"],\n",
    "    \"NFLX\" : [\"Netflix\"],\n",
    "    \"CSCO\" : [\"Cisco\"],\n",
    "    \"CMCSA\" : [\"Comcast\"],\n",
    "    \"PFE\" : [\"Pfizer\"],\n",
    "    \"KR\" : [\"Kroger\"],\n",
    "    \"V\" : [\"Visa\"],\n",
    "    \"SQ\" : [\"Square\"],\n",
    "    \"DIS\" : [\"Disney\"],\n",
    "    \"VZ\" : [\"Verizon\"],\n",
    "    \"GOOGL\" : [\"Google\"]\n",
    "    }\n",
    "companies = []\n",
    "keywords = []\n",
    "for l in ls:\n",
    "    companies.append(l)\n",
    "    keywords.append(ls.get(l))\n",
    "print(len(companies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch news articles\n",
    "newsapi = NewsApiClient(api_key='1cd3540192e6449e935a953fb7b02fcd')\n",
    "data = []\n",
    "for l in ls:\n",
    "    company = l\n",
    "    keywords = ls.get(l)\n",
    "    \n",
    "    r = newsapi.get_everything(q=keywords[0], from_param=start.strftime(\"%Y-%m-%d\"), \n",
    "                               to=end.strftime(\"%Y-%m-%d\"), language='en')\n",
    "    \n",
    "    total_results = r[\"totalResults\"]\n",
    "    if total_results == 0:\n",
    "        print(\"no results for \" + company)\n",
    "        print(\"keywords: \" + keyword[0])\n",
    "        print()\n",
    "        continue\n",
    "    \n",
    "    #find the first article with content\n",
    "    art_num = 0\n",
    "    content = r[\"articles\"][art_num][\"content\"]\n",
    "    while content is None:\n",
    "        art_num += 1\n",
    "        content = r[\"articles\"][art_num][\"content\"]\n",
    "    \n",
    "    print(\"Grabbed the \" + str(art_num) + \"th article for \" + company)\n",
    "    content = content.split(\"â€¦\")[0]\n",
    "    \n",
    "    if len(content) < 4:\n",
    "        print(\"no content for \" + company)\n",
    "        print(\"keywords: \" + keyword[0])\n",
    "        print()\n",
    "        continue\n",
    "    \n",
    "    publish_date = r[\"articles\"][art_num][\"publishedAt\"]\n",
    "    descr = r[\"articles\"][art_num][\"description\"]\n",
    "    source = r[\"articles\"][art_num][\"source\"]\n",
    "    \n",
    "    o = [{\"publish_date\" : publish_date, \"descr\" : descr, \"source\" : source, \"content\" : content}]\n",
    "    data.append(o)\n",
    "    \n",
    "#save the news data\n",
    "with open(r\"C:\\Users\\Brian\\Desktop\\ML\\project\\data\\news_data.json\", 'w') as outfile:\n",
    "    json.dump(data, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAL\n",
      "GE\n",
      "DAL\n",
      "BAC\n",
      "AMD\n",
      "F\n",
      "CCL\n",
      "UAL\n",
      "MRO\n",
      "MSFT\n",
      "WFC\n",
      "AAPL\n",
      "BA\n",
      "JBLU\n",
      "XOM\n",
      "T\n",
      "NOK\n",
      "JPM\n",
      "RCL\n",
      "MGM\n",
      "ZM\n",
      "LUV\n",
      "BP\n",
      "FB\n",
      "UBER\n",
      "CZR\n",
      "INTC\n",
      "TEVA\n",
      "ROKU\n",
      "NFLX\n",
      "CSCO\n",
      "CMCSA\n",
      "PFE\n",
      "KR\n",
      "V\n",
      "SQ\n",
      "DIS\n",
      "VZ\n",
      "GOOGL\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from iexfinance.stocks import get_historical_data\n",
    "#fetch data : Careful with this, i dont want to get charged...    \n",
    "# token=\"pk_b2644e7aed14466dbb1d102d2cdafc30\"\n",
    "stock_data = {}\n",
    "for company in companies:\n",
    "    print(company)\n",
    "    df = get_historical_data(company, start, end, token=\"pk_b2644e7aed14466dbb1d102d2cdafc30\")\n",
    "    stock_data.update({company : df})\n",
    "#save the stock data\n",
    "with open(r\"C:\\Users\\Brian\\Desktop\\ML\\project\\data\\stock_data.json\", 'w') as outfile:\n",
    "    json.dump(stock_data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open up the news json file\n",
    "with open(r\"C:\\Users\\Brian\\Desktop\\ML\\project\\data\\news_data.json\", \"r\") as f:\n",
    "    news_data = json.loads(f.read())\n",
    "#news_data[i] is article for companies[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open up the stock json file\n",
    "with open(r\"C:\\Users\\Brian\\Desktop\\ML\\project\\data\\stock_data.json\", \"r\") as f:\n",
    "    stock_data = json.loads(f.read())\n",
    "#stock_data.get('company') = stock data for company "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train doc2vec model\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "#try this https://radimrehurek.com/gensim/models/lsimodel.html\n",
    "doc_vec_size=20\n",
    "\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(common_texts)]\n",
    "model = Doc2Vec(documents, vector_size=doc_vec_size, window=2, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#use model to infer vectors for news data\n",
    "full_data = []\n",
    "for i,d in enumerate(news_data):\n",
    "    d=d[0]\n",
    "    v = model.infer_vector(d.get(\"content\").split())\n",
    "    o = {\"company\" : companies[i], \"docvec\" : v.tolist(), \"stock_data\" : stock_data.get(companies[i])}\n",
    "    full_data.append(o)\n",
    "with open(r\"C:\\Users\\Brian\\Desktop\\ML\\project\\data\\all_data_dvsize{}.json\".format(doc_vec_size), 'w') as outfile:\n",
    "    json.dump(full_data,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
